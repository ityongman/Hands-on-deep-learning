{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 1. 层和块",
   "id": "b14b73526944d4e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:08:24.153050Z",
     "start_time": "2025-09-22T12:08:24.146049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Relu: rectified linear unit 修正线性单元\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.randn(2, 20)\n",
    "print(net(X))"
   ],
   "id": "e9c74e89735825d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0062, -0.1392,  0.2363,  0.0832,  0.0243,  0.1784, -0.1006, -0.3280,\n",
      "         -0.1614,  0.3042],\n",
      "        [-0.2247, -0.1395,  0.1103,  0.1092, -0.1485,  0.0350, -0.1509, -0.1952,\n",
      "         -0.0477, -0.1296]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 2. 自定义块",
   "id": "db80b0545e62297"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:19:04.488520Z",
     "start_time": "2025-09-22T12:19:04.478843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    # 用模型参数声明层。这里，我们声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 隐藏层\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n",
    "    def forward(self, X):\n",
    "        # hidden_relu = nn.ReLU(self.hidden(X)) # TypeError: linear(): argument 'input' (position 1) must be Tensor, not ReLU\n",
    "        hidden_relu = F.relu(self.hidden(X))\n",
    "        return self.out(hidden_relu)\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(2, 20)\n",
    "print(net(X))"
   ],
   "id": "271d8b52dec7a619",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1740,  0.1725,  0.0923,  0.1195, -0.5226,  0.1948, -0.0990,  0.4433,\n",
      "          0.4237, -0.2867],\n",
      "        [-0.2174,  0.2314, -0.0177,  0.1429,  0.1685, -0.4289,  0.0787,  0.1734,\n",
      "         -0.4437,  0.1642]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 3. 顺序块",
   "id": "bdfa06be73cb98d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:25:16.557995Z",
     "start_time": "2025-09-22T12:25:16.550879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args): # enumerate()函数 将 索引和元素打包成元组\n",
    "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
    "            # 变量_modules中。_module的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module # 有序字典\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for module in self._modules.values():\n",
    "            X = module(X)\n",
    "        return X\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.randn(2, 20)\n",
    "print(net(X))"
   ],
   "id": "cf1539aee952ff2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7123,  0.2012, -0.5300, -0.1819, -0.1099, -0.1140,  0.4888,  0.5346,\n",
      "         -0.5012, -0.0522],\n",
      "        [-0.1565, -0.0852, -0.3347, -0.0873, -0.2728, -0.3032,  0.2280,  0.0763,\n",
      "         -0.1513,  0.0404]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 4. 在前向传播函数中执行代码",
   "id": "4dde3af36bbbfc06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:39:11.982919Z",
     "start_time": "2025-09-22T12:39:11.974720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class FixHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        print('X', X)\n",
    "        X = self.linear(X)\n",
    "        # 使用创建的常量参数以及relu和mm函数\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        X = self.linear(X)\n",
    "        # 控制流\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "\n",
    "net = FixHiddenMLP()\n",
    "X = torch.randn(2, 20)\n",
    "print(net(X))"
   ],
   "id": "c31f7644cc049f97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[ 0.3810,  0.9665, -0.3679, -1.4356,  0.1412,  0.2186, -0.1983, -0.1711,\n",
      "          0.5136,  0.5563, -0.5663, -2.0419,  0.2936,  1.1343,  1.3069, -0.2156,\n",
      "         -1.2543,  0.0417, -0.9581, -1.6532],\n",
      "        [-0.2604, -0.3824, -0.9645,  0.8524, -1.0908,  0.4778, -1.2645, -1.6788,\n",
      "         -0.3141, -0.4336, -2.6020, -0.3865, -1.4434, -0.2953, -0.0914,  0.2393,\n",
      "         -0.0936,  0.6398,  1.4310, -0.1027]])\n",
      "tensor(-0.1768, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 可以混合搭配各种组合块的方法",
   "id": "b4249d1cef73dfe7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:39:35.418979Z",
     "start_time": "2025-09-22T12:39:35.410980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(20, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 32), nn.ReLU()\n",
    "                                 )\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixHiddenMLP())\n",
    "\n",
    "X = torch.randn(2, 20)\n",
    "print(chimera(X))"
   ],
   "id": "75d007a5aa2aa0f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[ 2.5135e-01, -1.3667e-01,  2.4794e-01,  1.4598e-02, -1.5441e-01,\n",
      "         -4.6506e-02, -2.0240e-02,  1.4868e-01,  9.2175e-02,  1.7458e-01,\n",
      "          1.0291e-01, -2.2695e-01,  1.8266e-01, -2.6253e-01, -2.0054e-01,\n",
      "          1.2006e-01, -1.0820e-01, -1.2115e-01,  6.0168e-02, -5.5276e-05],\n",
      "        [ 1.3988e-01, -1.0401e-01,  1.7652e-01,  2.0877e-03, -8.2170e-02,\n",
      "         -1.5255e-02, -6.9511e-02,  1.4035e-01,  1.5811e-02,  2.4414e-01,\n",
      "          6.8375e-02, -1.3626e-01,  4.8868e-02, -1.3627e-01, -1.5445e-01,\n",
      "          1.9012e-01, -1.2681e-01, -1.5437e-01,  1.0323e-01,  1.1605e-02]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(-0.0109, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T12:39:32.304541Z",
     "start_time": "2025-09-22T12:39:32.302141Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a947e1b821cb07cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "77d2972c590cb68b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
